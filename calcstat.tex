\documentclass[11pt,leqno,letterpaper]{article}
% Final Project for AP Statistics
% Ideas by Jeremiah Gelb
% LaTeX typesetting by Blaise Whitesell
\usepackage[utf8]{inputenc}
\usepackage[intlimits]{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mdframed}
% \usepackage{textcomp}
\usepackage{booktabs}
\usepackage{xparse}
\usepackage{tikz}
\usetikzlibrary{calc}
% \usepackage{graphicx}
% \usepackage{lmodern}
\usepackage[left=4cm,right=4cm,top=3.5cm,bottom=3.5cm]{geometry}
% Packages loaded
\title{\Huge{The Calculus of Statistics}}
\author{\Large{Blaise Whitesell} \and \Large{Jeremiah Gelb}}
% \date{\today}
% Header/footer config
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\lfoot{}
\cfoot{}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
% End header/footer config
\begin{document}
% Begin hack commands
\newcommand{\bdef}[1]{\textbf{#1}} % Bold definitions
\newcommand{\dx}{\:\mathrm{d}x} % Integral dx
\newcommand{\dt}{\:\mathrm{d}t} % Integral dt
\newcommand{\dth}{\:\mathrm{d}\theta} % Integral dtheta
\newcommand{\du}{\:\mathrm{d}u} % Integral du
\newcommand{\dv}{\:\mathrm{d}v} % Integral dv
\newcommand{\dr}{\:\mathrm{d}r} % Integral dr
\newcommand{\deriv}[2]{\dfrac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\derivp}[2]{\dfrac{\partial \;\! #1}{\partial \;\! #2}}
\theoremstyle{definition} \newtheorem{problem}{Problem}
\newcommand{\AM}{\textsc{am}}
% Tikz for tabular integration
\tikzset{Arrow Style/.style={text=black, font=\boldmath}}
\newcommand{\tikzmark}[1]{%
\tikz[overlay, remember picture, baseline] \node (#1) {};%
}
\newcommand*{\XShift}{0.5em}
\newcommand*{\YShift}{0.5ex}
\NewDocumentCommand{\DrawArrow}{s O{} m m m}{%
\begin{tikzpicture}[overlay,remember picture]
\draw[->, thick, Arrow Style, #2] 
($(#3.west)+(\XShift,\YShift)$) -- 
($(#4.east)+(-\XShift,\YShift)$)
node [midway,above] {#5};
\end{tikzpicture}%
}
% End hack commands
\maketitle
\thispagestyle{fancy}
\vspace{2 em}
\section{Probability Distribution Functions}
\subsection{Probability Density Functions}
A probability density function (\bdef{PDF}) describes
the relative likelihood $f(x)$ of possible outcomes
for a continuous random variable.
\begin{itemize}
\item The probability of any $x$ occurring is either positive or zero,
so a PDF can never be negative.
\[
f(x) \geq 0 \quad \text{for all }x.
\]
\item The area under the curve must equal unity
\[
\int_a^b f(x)\dx = 1
\]
where $a$ and $b$ are the lower and upper bounds,
often $-\infty$ and $\infty$.
\end{itemize}
\subsection{Cumulative Distribution Functions}
A cumulative distribution function (\bdef{CDF}) gives
the probability $F(x)$ that the outcome of a
continuous random variable will be less than or equal to $x$.
\begin{itemize}
\item The CDF is related to the PDF by this integral:
\[
F(x) = \int_a^x f(t) \dt \quad \text{for } a \leq x \leq b.
\]
% where $F(x)$ is the CDF and $f(x)$ is the PDF.
\item A CDF is monotonically increasing on the interval $(a,b)$.
\[
F(a) = 0 \qquad F(b) = 1
\]
\end{itemize}
\subsection{Using Calculus}
To find the probability of an outcome in a certain range,
one can integrate the PDF over that interval
$(c,d)$ contained in $(a,b)$.
\[
\int_c^d f(x) \dx \quad = F(d) - F(c)
\]
This gives the area under the curve, corresponding to the probability.

\section{The Uniform Distribution}
\subsection{Definition}
A uniform distribution describes a continuous random variable
where every outcome on an interval $(a,b)$ is equally likely.
\[
f(x) = \kappa
\]
\subsection{Implications}
\begin{itemize}
\item The distribution looks like a rectangle
with length $b-a$ and height $\kappa$
\item Area $= 1 = (b-a)\cdot \kappa$
% Gratuitous calculus follows:
\[
\int_a^b \frac{1}{b-a} \dx = \frac{x}{b-a}\bigg|_a^b
= \frac{b}{b-a} - \frac{a}{b-a} = \frac{b-a}{b-a} = 1
\]
\item Therefore, we have an explicit definition for $\kappa$:
\[
\kappa = \frac{1}{b-a}
\]
\end{itemize}
\subsection{General form}
The uniform distribution has two parameters: the bounds $a$ and $b$.
\begin{align*}
\tag{PDF}
f(x)&=
\begin{cases}
\frac{1}{b-a} & \text{for } a \leq x \leq b,\\
0 & \text{otherwise}.
\end{cases} \\
\tag{CDF}
F(x)&=
\begin{cases}
0 & \text{for } x < a,\\
\frac{x-a}{b-a} & \text{for } a \leq x < b,\\
1 & \text{for } x \geq b.
\end{cases}
\end{align*}
The CDF increases linearly on the interval $(a,b)$.

\begin{mdframed}
\begin{problem}
In the game ``Spin to Win'', the player spins a giant roulette wheel
with 200 spaces. One is marked ``Win'', one is marked ``Lose'',
and the remaining 198 are marked ``Spin Again''.
What is the probability of losing on the first spin?
\begin{proof}[Solution]
There are 200 spaces,
exactly one of which corresponds to losing immediately.
The continuous range of values can be modeled as
a uniform distribution from 0$^\circ$ to 360$^\circ$.
\[
1/200 \times 360^\circ = 1.8^\circ
\]
\[
\int_0^{1.8} \frac{1}{360} \dth
= \frac{\theta}{360} \bigg|_0^{1.8} 
= \frac{1.8}{360} - \frac{0}{360} = 0.005
\]
Interestingly enough, this is equivalent to $1/200$.
\end{proof}
\end{problem}
\end{mdframed}

\section{The Exponential Distribution}
\subsection{Introduction}
An exponential distribution can be used to model events that occur
independently at a constant average rate.

\begin{mdframed}
\begin{problem}
250 kids at a frat party are randomly getting sick at a continuous
rate of 20\% per hour, beginning at 12:00\AM .
What is the probability that Chad gets sick between 2:00\AM{ }and 3:00\AM ?
\begin{proof}[Solution]
Let $t=0$ at 12:00\AM .
The number of kids who are not sick is given by $250e^{-.2t}$,
and the number of kids who are sick is given by
$250 - 250e^{-.2t}$.
Therefore, the proportion of kids who are sick after $t$ hours is
\[
\frac{250 - 250e^{-.2t}}{250} \quad = 1 - e^{-.2t}
\]
This is equivalent to the probability of being sick after $t$ hours,
which is the CDF. To find the PDF, simply take a derivative.
\begin{align*}
\int_0^t f(x) \dx &= 1 - e^{-.2t}\\
\deriv{}{t} \int_0^t f(x) \dx &= \deriv{}{t} (1 - e^{-.2t})\\
f(x) &= .2e^{-.2t}
\end{align*}
Now that we know the PDF, we integrate it between $t=2$ and $t=3$.
\[
\int_2^3 .2e^{-.2t} = -e^{-.2t}\Big|_2^3 = -e^{-.6} - (-e^{-.4})
= .1215
\]
Note that we could also have found this answer by
finding the difference between $F(3)$ and $F(2)$,
without using the PDF at all.
\[
\left(1 - e^{-.2t}\right)\Big|_{t=3} -
\left(1 - e^{-.2t}\right)\Big|_{t=2} = .1215
\]
Using either of these methods, the probability that Chad will get sick
between 2:00\AM{} and 3:00\AM{} is $.1215$.
\end{proof}
\end{problem}
\end{mdframed}

\subsection{General Form}
The exponential distribution has one parameter $k$,
where $0<k<1$. It is known as the rate parameter.
\begin{align*}
\tag{PDF}
f(t) &= ke^{-kt} \\
\tag{CDF}
F(t) &= 1-e^{-kt}
\end{align*}
It can be shown that the area under the PDF is 1.
\[
\lim_{b\to \infty} \int_0^b ke^{-kt} =
\lim_{b\to \infty} -e^{-kt}\bigg|_0^b =
\lim_{b\to \infty} -e^{-k(b)} - \left(-e^{-k(0)}\right) =
0 - (-1) = 1
\]

\section{Properties of Random Variables}
\subsection{Expected Value}
The expected value of a random variable (also known as the mean)
can be thought of intuitively as the long-run average of its outcomes.
For a discrete random variable, it is the probability-weighted
average of all possible outcomes, which may be calculated directly.

\begin{mdframed}
\begin{problem}
What is the expected value for the roll of a six-sided die?
\begin{proof}[Solution]
The possible outcomes are 1, 2, 3, 4, 5, and 6, each occurring
with probability $\frac{1}{6}$.
\[
\frac{1}{6}(1)+ \frac{1}{6}(2)+ \frac{1}{6}(3)+
\frac{1}{6}(4)+ \frac{1}{6}(5)+ \frac{1}{6}(6) = 3.5
\]
\end{proof}
\end{problem}
\end{mdframed}

The general formula for the expected value of a
discrete random variable is
\[
\sum_{i=1}^k x_i p_i
\]
where $p_i$ is the probability of outcome $x_i$
of $k$ possible outcomes.

The formula for expected value can be extended to continuous
random variables by replacing the sum with an integral.
\[
\mu = \int_a^b x\cdot f(x)\dx
\]
It follows that this is the mean of the PDF $f(x)$.

\begin{mdframed}
\begin{problem}
During the frat party, when can Chad expect to get sick?
\begin{proof}[Solution]
Use the formula for expected value of a continuous random variable.
\begin{align*}
\tag*{Setup}
\int_0^\infty x\cdot \left(.2e^{-.2x}\right)\dx \qquad \qquad \\
\tag*{Integrate by parts}
u=x \quad \du = 1\dx \quad \dv = .2e^{-.2x}\dx \quad v = -e^{-.2x} \\
\tag*{Antiderivative}
-xe^{-.2x} - \int -e^{-.2x}\dx \quad = -xe^{-.2x} -5e^{-.2x} \\
\tag*{Improper integral}
\lim_{b\to \infty}\left(-5-x\right)\left(e^{-.2x}\right)\Big|_0^b
\qquad = 5
\end{align*}
% Expand if time permits!
Chad can expect to get sick around 5:00\AM{}.
\end{proof}
\end{problem}
\end{mdframed}
\subsection{Median}
The median $M$ is the value of $x$ for which
\[
P(x\leq M) = .5 \quad \text{ and } \quad P(x\geq M) = .5
\]
It follows that the median is an M such that
\[
\int_a^M f(x) \dx = \frac{1}{2}
\]
\begin{mdframed}
\begin{problem}
At what time are half the kids at the frat party sick?
\begin{proof}[Solution]
Solve for the upper bound for the integral using
the Fundamental Theorem of Calculus.
\begin{align*}
\int_0^M .2e^{-.2t}\dt &= 0.5 \\
-e^{-.2t}\Big|_0^M &= 0.5 \\
-e^{-.2M}-\left(-e^{-2(0)}\right) &= 0.5 \\
-e^{-.2M} +1 &= 0.5 \\
e^{-.2M} &= 0.5 \\
-.2M &= \ln 0.5 \\
M &= 3.4657
\end{align*}
Half the kids at the party will be sick by 3:28\AM{}.
\end{proof}
\end{problem}
\end{mdframed}
\subsection{Variance}
Variance is a measure of the spread of a distribution.
It is used to describe the average distance of an outcome
from the expected value.

A naive method of calculating variance would be
\[
\tag{Spurious}
\int_a^b (x - \mu ) f(x) \dx
\]
The problem with this method is that negative and positive values of
$(x- \mu)$ cancel each other out. Instead we can compute
\begin{align*}
\text{Absolute deviation} &=
\int_a^b \big| x - \mu \big| f(x) \dx \\
\tag*{or}
\text{Variance} = \text{Var}(x) &= \int_a^b {(x - \mu )}^2 f(x) \dx
\end{align*}
The second method, in which the term $(x- \mu)$ is squared,
is preferred for reasons which are beyond the scope of this text.
Note that squaring the values gives a greater weight to outcomes
that are further from the expected value.

The square root of the variance is known as the
\bdef{standard deviation}.
\[
\tag{Wow!}
\sqrt{\text{Var}(x)} = \sigma
\]

\begin{mdframed}
\begin{problem}
Find the standard deviation of the time
someone at this frat party gets sick.
\begin{proof}[Solution]
Solve for the variance using the formula.
\[
\int_0^{\infty} \left( t-5 \right)^2 \cdot
\left( .2e^{-.2t} \right) \dt
\]
% Begin tabular integration
\[
{\renewcommand{\arraystretch}{1.5}
\begin{array}{rc @{\hspace*{5 em}} cr}\toprule
u &&& \dv \\\cmidrule{1-4}
t^2-10t+25 &\tikzmark{Left 1} & \tikzmark{Right 1}&.2e^{-.2t} \\
2t-10 &\tikzmark{Left 2} & \tikzmark{Right 2}&-e^{-.2t} \\      
2 &\tikzmark{Left 3} & \tikzmark{Right 3}&5e^{-.2t} \\      
0 &\tikzmark{Left 4} & \tikzmark{Right 4}&-25e^{-.2t} \\
\bottomrule
\end{array}}
\]
\DrawArrow{Left 1}{Right 2}{$+$}%
\DrawArrow{Left 2}{Right 3}{$-$}%
\DrawArrow{Left 3}{Right 4}{$+$}%
% End tabular integration
\begin{align*}
\lim_{b\to \infty}
\left( t^2-10t+25 \right) \left( -e^{-.2t} \right)
- \left( 2t-10 \right) \left( 5e^{-.2t} \right)
+ \left( 2 \right) \left( -25e^{-.2t} \right)
\bigg|_0^b \\
e^{-.2(0)} \Big(
25(-1) - (-10)(5) +2(-25) \Big) =25 \\
\tag*{Standard deviation is the square root of variance}
\sqrt{25}= 5
\end{align*}
The standard deviation is 5 hours.
% FIX THIS!!!!!!!!!!!!!
\end{proof}
\end{problem}
\end{mdframed}
\section{The Normal Distribution}
\subsection{Description}
A Normal distribution is a bell-shaped curve
with special properties that are useful in statistics.
It is a continuous distribution over the set of real numbers
described by two parameters $\mu$ and $\sigma$, which
correspond to its mean and standard deviation.
\[
\tag{PDF}
f(x) = 
N(x,\mu ,\sigma) = \frac{1}{\sigma \sqrt{2 \pi}} \cdot
e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}
\]
\begin{proof}
The area $Q$ under a Normal PDF is unity.
\[
\tag*{Show that}
Q = 1 =
\int_{-\infty}^{\infty} \frac{1}{\sigma \sqrt{2 \pi}} \cdot
e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2} \dx
\]
\[
\tag*{Let}
u=\frac{x-\mu}{\sigma} \qquad
\du = \frac{\!\dx}{\sigma} \qquad \dx = \sigma \du
\]
\begin{align*}
Q &= \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} \cdot
e^{-\frac{1}{2}u^2} \du \\
Q^2 &= \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} \cdot
e^{-\frac{1}{2}u^2} \du \cdot
\int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} \cdot
e^{-\frac{1}{2}v^2} \dv \\
Q^2 &= \frac{1}{2\pi} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
e^{-\frac{1}{2}\left(u^2 + v^2 \right)} \du \dv
\end{align*}
\begin{align*}
\tag*{Convert to polar form}
u = r \cos \theta \qquad v = r \sin \theta \qquad
u^2+v^2=r^2 \\
\tag*{Jacobian}
\begin{vmatrix}
\derivp{u}{r}&\derivp{u}{\theta}\\ \\
\derivp{v}{r}&\derivp{v}{\theta}
\end{vmatrix} =
\begin{vmatrix}
\cos \theta & -r \sin \theta \\
\sin \theta & r \cos \theta
\end{vmatrix} =
\left|r\cos^2\theta+r\sin^2\theta\right| = r
\end{align*}
\begin{align*}
Q^2 &= \frac{1}{2\pi} \int_{0}^{2\pi} \int_{0}^{\infty}
e^{-\frac{1}{2}r^2} \, r \dr \dth \\
\tag*{Separate and cancel}
Q^2 &= \frac{1}{2\pi} \int_{0}^{2\pi} \dth \cdot
\int_{0}^{\infty} e^{-\frac{1}{2}r^2} \, r \dr \\
\tag*{$t=r^2 \qquad \dt= 2r \dr$}
Q^2 &= \int_{0}^{\infty} \frac{1}{2} e^{-\frac{1}{2}t} \dt \\
Q^2 &= \lim_{b\to \infty} \left(-e^{-\frac{1}{2}t}\right)\Big|_0^b \\
Q^2 &= 1 \\
\tag*{$\therefore$}
Q&=1
\end{align*}
\end{proof}
\end{document}
